{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_sign_(작업중).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1pJd7meI7sGNB8LrpmE-p6Eiytr9y8Hyy",
      "authorship_tag": "ABX9TyNgwsuQMQDsjPuX41fERpsM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjungmo/SBA2020_FinalProject/blob/main/traffic_sign_(%EC%9E%91%EC%97%85%EC%A4%91).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG5W-FF0H4oS"
      },
      "source": [
        "# /content/drive/My Drive/lane/traffic_signs_classification.zip\n",
        "\n",
        "path_to_zip_file = '/content/drive/My Drive/lane/traffic_sign_classification.zip'\n",
        "directory_to_extract_to = '/content/trafficsign'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "  zip_ref.extractall(directory_to_extract_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwpX_3seHrBb",
        "outputId": "ce1d7d4d-1659-4fec-992f-334b8bcd3a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "# data_gen 코드 모듈을 제일 먼저 작성한다.\n",
        "\n",
        "\n",
        "def traffic_data_gen(data_path, model_size):  # 데이터셋의 위치를 받고 모델사이즈를 받아서 모델에 넣을 데이터 생성\n",
        "\n",
        "    label = 0\n",
        "    data_set = []\n",
        "    traffic_dict = []\n",
        "    save_flag = 0\n",
        "    count = 0\n",
        "\n",
        "    train_data_path = \"trafficdata/train/\"\n",
        "    test_data_path = \"trafficdata/test/\"\n",
        "    traffic_name_txt = \"traffic_name.txt\"  # 나중에 파일 라벨 확인할 txt 문서 만들어 둔 것.(편의상)\n",
        "\n",
        "    if not os.path.isdir(train_data_path):  # 해당 디렉토리에 없다면 만들어라\n",
        "        os.makedirs(train_data_path)\n",
        "    if not os.path.isdir(test_data_path):\n",
        "        os.makedirs(test_data_path)\n",
        "\n",
        "    if len(glob.glob(train_data_path + \"*.jpg\")) > 10:  # 훈련 데이터 경로의 이미지가 10개를 초과하면 save_flag= 1\n",
        "        save_flag = 1  # 즉 이미 있으니 저장 안한다는 말. 읽어오기만 해도 된다.\n",
        "\n",
        "    # 데이터가 없다면\n",
        "    # 훈련 데이터 경로에 이미지가 없다면( 9개 이하라면)\n",
        "    if save_flag == 0:\n",
        "\n",
        "        fld_list = glob.glob(data_path + '/*')  # 폴더의 리스트를 가져온다. 데이터 경로의 모든 폴더들\n",
        "        for i in tqdm(fld_list):  # 여기서 i는 폴더리스트에 있는 요소 하나다. 즉 폴더 하나가 라벨 하나다.\n",
        "            img_list = i + '/*.jpg'  # img_list는 폴더리스트에 들어간 이미지들의 리스트경로를 가져오게 하는  값 설정\n",
        "            img_list = glob.glob(img_list)  # 해당 리스트들을 모두 파일로 가져온다.\n",
        "            for j in img_list:  # j는 폴더안의 이미지 하나 하나\n",
        "                img = cv2.imread(j)  # 이미지를 읽어서\n",
        "                # img = cv2.resize(img, (model_size, model_size))  # resize해주고\n",
        "                traffic_name = i.replace('/content/trafficsign/traffic_signs_classification/myData', '~~')   # 폴더명별로 되어있는 라벨 이름만 남김.\n",
        "                data_set.append([img, label])  # 이미지와 그에따른 라벨을 데이터셋에 추가한다.\n",
        "            traffic_dict.append(traffic_name)  # 라벨 사전에는 j의 포문 후 라벨 이름을 추가한다.\n",
        "            label += 1\n",
        "#                 img_list 포문이 돌때마다 라벨별 폴더의 이미지를 읽어서 라벨링해준다.\n",
        "#                     그에 맞는 라벨 이름도 라벨 사전에 추가된다.\n",
        "\n",
        "\n",
        "        with open(traffic_name_txt, 'w') as txt:\n",
        "            for n in traffic_dict:  # 라벨 사전에 적힌 이름들( 폴더명) 개수 만큼 돌면서\n",
        "                txt.writelines(str(n))  # txt파일에 이름을 쭉 write한다.\n",
        "                txt.writelines(\" \")  # 한칸씩 띄어쓰면서\n",
        " \n",
        "        indexer = int(len(data_set) * 0.8)  # 훈련/시험 데이터 나누는 비율\n",
        "\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        x_test = []\n",
        "        y_test = []\n",
        "\n",
        "        random.shuffle(data_set)  # 전체 데이터 섞어줌\n",
        "\n",
        "        count = 0\n",
        "        for i in tqdm(range(0, indexer)):  # 훈련데이터\n",
        "            x_train.append(data_set[i][0])\n",
        "            y_train.append(data_set[i][1])  # 위에서 [img, label]로 append해서 이렇게 [i][0] , [i][1]\n",
        "\n",
        "            save_img_path = train_data_path + \"%d.jpg\" % count  # 이미지 경로\n",
        "            save_label_file = train_data_path + \"%d.txt\" % count  # 라벨(텍스트) 경로\n",
        "\n",
        "            cv2.imwrite(save_img_path, data_set[i][0])  # 이미지 저장\n",
        "            with open(save_label_file, 'w') as txt:  # 텍스트 저장 라벨링 한 숫자에 맞아떨어지게\n",
        "                txt.writelines(str(data_set[i][1]))\n",
        "            count += 1\n",
        "\n",
        "        count = 0  # 시험 데이터도 돌려야 해서 local변수 선언 해준 것이다. 위의 count와 영향 없게\n",
        "        for i in tqdm(range(indexer, len(data_set))):\n",
        "            x_test.append(data_set[i][0])\n",
        "            y_test.append(data_set[i][1])\n",
        "\n",
        "            save_img_path = test_data_path + \"%d.jpg\" % count  # 이미지 경로\n",
        "            save_label_file = test_data_path + \"%d.txt\" % count  # 라벨(텍스트) 경로\n",
        "\n",
        "            cv2.imwrite(save_img_path, data_set[i][0])  # 이미지 저장\n",
        "\n",
        "            with open(save_label_file, 'w') as txt:  # 텍스트 저장\n",
        "                txt.writelines(str(data_set[i][1]))\n",
        "            count += 1\n",
        "\n",
        "        return x_train, y_train, x_test, y_test, traffic_dict\n",
        "\n",
        "    elif save_flag == 1:  # 이미 파일이 준비되어 있는 경우\n",
        "\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        x_test = []\n",
        "        y_test = []\n",
        "\n",
        "        train_data_list = glob.glob(train_data_path + \"*.jpg\")  # 데이터가 이미 존재하니까. 이미지 불러옴\n",
        "        test_data_list = glob.glob(test_data_path + \"*.jpg\")\n",
        "\n",
        "\n",
        "        for i in tqdm(range(0, len(train_data_list))):  # 이미지 하나하나 for문돌리면서\n",
        "            file = train_data_list[i]  # i번째 이미지\n",
        "            img = cv2.imread(file)  # 읽고\n",
        "            label_path = file.replace(\".jpg\", \".txt\")  # 라벨 데이터 읽기 위해 path만듬\n",
        "            with open(label_path, 'r') as txt:  # 라벨 데이터 txt안에서 라벨 읽어옴\n",
        "                label = txt.readlines()\n",
        "            label = int(label[0])  # 각 이미지 별 라벨 값을 얻는다.\n",
        "            x_train.append(img)  # 이미지는 x에\n",
        "            y_train.append(label)  # 라벨은 y에 넣는다\n",
        "        # 테스트 데이터도 마찬가지\n",
        "        for i in tqdm(range(0, len(test_data_list))):\n",
        "            file = test_data_list[i]\n",
        "            img = cv2.imread(file)\n",
        "            label_path = file.replace(\".jpg\", \".txt\")\n",
        "            with open(label_path, 'r') as txt:\n",
        "                label = txt.readlines()\n",
        "            label = int(label[0])\n",
        "            x_test.append(img)\n",
        "            y_test.append(label)\n",
        "        # 라벨 이름을 불러오기 위해 만들어둔 딕셔너리에서 찾아오는 방법\n",
        "        with open(traffic_name_txt, 'r') as txt:\n",
        "            label = txt.readlines()\n",
        "            traffic_dict = label[0].split(\"~~\")  # 만든 파일이 모두 띄어쓰기로 이루어진것\n",
        "\n",
        "        return x_train, y_train, x_test, y_test, traffic_dict\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data_path = \"/content/trafficsign/traffic_signs_classification/myData\"\n",
        "    model_size = 32\n",
        "    x_train, y_train, x_test, y_test, traffic_dict = traffic_data_gen(data_path, model_size)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 43/43 [00:04<00:00,  9.70it/s]\n",
            "100%|██████████| 58511/58511 [00:06<00:00, 8960.86it/s]\n",
            "100%|██████████| 14628/14628 [00:01<00:00, 9263.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgIJAQztutrA",
        "outputId": "690d8ad1-99cf-4a87-9ac8-e550497729d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "traffic_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['~~/End of speed limit (80kmh)',\n",
              " '~~/Road work',\n",
              " '~~/Speed limit (100kmh)',\n",
              " '~~/Pedestrians',\n",
              " '~~/Vechiles over 3.5 metric tons prohibited',\n",
              " '~~/Right-of-way at the next intersection',\n",
              " '~~/End of all speed and passing limits',\n",
              " '~~/No passing',\n",
              " '~~/Speed limit (80kmh)',\n",
              " '~~/No passing for vechiles over 3.5 metric tons',\n",
              " '~~/Dangerous curve to the left',\n",
              " '~~/End of no passing',\n",
              " '~~/Speed limit (20kmh)',\n",
              " '~~/Stop',\n",
              " '~~/Beware of ice snow',\n",
              " '~~/Road narrows on the right',\n",
              " '~~/Children crossing',\n",
              " '~~/Go straight or left',\n",
              " '~~/Traffic signals',\n",
              " '~~/Yield',\n",
              " '~~/Dangerous curve to the right',\n",
              " '~~/Priority road',\n",
              " '~~/Speed limit (60kmh)',\n",
              " '~~/Turn right ahead',\n",
              " '~~/Speed limit (120kmh)',\n",
              " '~~/Roundabout mandatory',\n",
              " '~~/Keep right',\n",
              " '~~/Wild animals crossing',\n",
              " '~~/Turn left ahead',\n",
              " '~~/Bicycles crossing',\n",
              " '~~/Slippery road',\n",
              " '~~/Bumpy road',\n",
              " '~~/End of no passing by vechiles over 3.5 metric tons',\n",
              " '~~/No vechiles',\n",
              " '~~/Keep left',\n",
              " '~~/Speed limit (50kmh)',\n",
              " '~~/No entry',\n",
              " '~~/Speed limit (70kmh)',\n",
              " '~~/Speed limit (30kmh)',\n",
              " '~~/Double curve',\n",
              " '~~/Go straight or right',\n",
              " '~~/General caution',\n",
              " '~~/Ahead only']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KllN8SC2Aov",
        "outputId": "4cf33e4f-b9a8-4ab2-a9e9-3175a03b0c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27,\n",
              " 35,\n",
              " 26,\n",
              " 8,\n",
              " 2,\n",
              " 36,\n",
              " 5,\n",
              " 7,\n",
              " 24,\n",
              " 42,\n",
              " 26,\n",
              " 37,\n",
              " 22,\n",
              " 4,\n",
              " 16,\n",
              " 2,\n",
              " 41,\n",
              " 32,\n",
              " 41,\n",
              " 2,\n",
              " 9,\n",
              " 19,\n",
              " 38,\n",
              " 14,\n",
              " 26,\n",
              " 9,\n",
              " 27,\n",
              " 33,\n",
              " 2,\n",
              " 21,\n",
              " 38,\n",
              " 38,\n",
              " 38,\n",
              " 21,\n",
              " 13,\n",
              " 37,\n",
              " 7,\n",
              " 19,\n",
              " 19,\n",
              " 27,\n",
              " 34,\n",
              " 37,\n",
              " 1,\n",
              " 21,\n",
              " 19,\n",
              " 5,\n",
              " 9,\n",
              " 41,\n",
              " 28,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OtfMg8qr383",
        "outputId": "0808ce77-bbe5-4c28-e37e-139cbe653fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "m_name = \"traffic_1\"\n",
        "lr = 0.03\n",
        "epochs=10\n",
        "bath_size = 32\n",
        "\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_train = x_train.astype('float32')\n",
        "X_test = x_test.astype('float32')\n",
        "x_train = X_train / 255.0\n",
        "x_test = X_test / 255.0\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 43)\n",
        "y_test = keras.utils.to_categorical(y_test, 43)\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = keras.layers.Conv2D(3, kernel_size=3,padding=\"same\")(inputs)\n",
        "x = keras.layers.Activation(\"relu\")(x)\n",
        "x = keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "\n",
        "x = keras.layers.Conv2D(8, kernel_size=3,padding=\"same\")(x)\n",
        "x = keras.layers.Activation(\"relu\")(x)\n",
        "x = keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "\n",
        "x = keras.layers.Conv2D(16, kernel_size=3,padding=\"same\")(x)\n",
        "x = keras.layers.Activation(\"relu\")(x)\n",
        "x = keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "\n",
        "x = keras.layers.Conv2D(128, kernel_size=3,padding=\"same\")(x)\n",
        "x = keras.layers.Activation(\"relu\")(x)\n",
        "x = keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "x = keras.layers.Flatten()(x)\n",
        "x= keras.layers.Dense(64)(x)\n",
        "x = keras.layers.Activation(\"relu\")(x)\n",
        "x= keras.layers.Dense(43)(x)\n",
        "\n",
        "out = keras.layers.Activation(\"softmax\")(x)\n",
        "model = keras.models.Model(inputs, out)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "if not os.path.isdir('./saved_models'):\n",
        "    os.makedirs('./saved_models')\n",
        "if not os.path.isdir('./logs'):\n",
        "    os.makedirs('./logs')\n",
        "\n",
        "log_dir = os.path.join(\n",
        "    \"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        ")\n",
        "\n",
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
        "                                               patience=20,\n",
        "                                               verbose=1, factor=0.5),\n",
        "             keras.callbacks.ModelCheckpoint(filepath='./saved_models/'+m_name+'-{epoch:05d}.h5',\n",
        "                                             verbose=1,\n",
        "                                             period=5),\n",
        "             keras.callbacks.TensorBoard(log_dir),\n",
        "             keras.callbacks.EarlyStopping(monitor='loss', patience=25, verbose=1)]\n",
        "model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epochs, batch_size=bath_size, callbacks=callbacks, verbose=1)\n",
        "\n",
        "scores = model.evaluate(x_test,y_test, verbose=2)\n",
        "print(\"Acc:\", scores[1]*100)\n",
        "model.save('./saved_models/'+m_name+'_final.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(58511, 32, 32, 3) (58511, 43) (14628, 32, 32, 3) (14628, 43)\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 3)         84        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 8)         224       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 128)         18560     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 43)                2795      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 43)                0         \n",
            "=================================================================\n",
            "Total params: 55,663\n",
            "Trainable params: 55,663\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/10\n",
            "   1/1829 [..............................] - ETA: 0s - loss: 3.7500 - accuracy: 0.0000e+00WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0085s vs `on_train_batch_end` time: 0.0320s). Check your callbacks.\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 1.6093 - accuracy: 0.5562 - val_loss: 0.7235 - val_accuracy: 0.7824\n",
            "Epoch 2/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.4530 - accuracy: 0.8663 - val_loss: 0.3723 - val_accuracy: 0.8884\n",
            "Epoch 3/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.2716 - accuracy: 0.9185 - val_loss: 0.2560 - val_accuracy: 0.9247\n",
            "Epoch 4/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1942 - accuracy: 0.9407 - val_loss: 0.2297 - val_accuracy: 0.9293\n",
            "Epoch 5/10\n",
            "1819/1829 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9539\n",
            "Epoch 00005: saving model to ./saved_models/traffic_1-00005.h5\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1494 - accuracy: 0.9539 - val_loss: 0.1619 - val_accuracy: 0.9509\n",
            "Epoch 6/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1255 - accuracy: 0.9602 - val_loss: 0.1394 - val_accuracy: 0.9573\n",
            "Epoch 7/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.1079 - accuracy: 0.9661 - val_loss: 0.1269 - val_accuracy: 0.9644\n",
            "Epoch 8/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9710 - val_loss: 0.1459 - val_accuracy: 0.9567\n",
            "Epoch 9/10\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0833 - accuracy: 0.9738 - val_loss: 0.1335 - val_accuracy: 0.9610\n",
            "Epoch 10/10\n",
            "1826/1829 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9762\n",
            "Epoch 00010: saving model to ./saved_models/traffic_1-00010.h5\n",
            "1829/1829 [==============================] - 7s 4ms/step - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.1324 - val_accuracy: 0.9617\n",
            "458/458 - 1s - loss: 0.1324 - accuracy: 0.9617\n",
            "Acc: 96.17172479629517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HG7buCwxpQ1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCLRPGWKO0Xr"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/saved_models/traffic_1_final.h5')\n",
        "pred = np.argmax(model.predict(x_test[:5]), axis=1)\n",
        "for i in range(len(pred)):\n",
        "  img = x_test[i]\n",
        "  real_name = traffic_dict[pred[i]]\n",
        "  plt.title(real_name)\n",
        "  plt.imshow(img[:, :, 0], 'gray')\n",
        "  plt.show()\n",
        "  # print(real_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osJQEgFhnjiF",
        "outputId": "860a0c60-b761-4d2e-d072-a501e048346f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prpe = []\n",
        "for i in range(0, 199):\n",
        "  x_test_x = np.expand_dims(x_test[i], axis=0)\n",
        "  \n",
        "  pred_y = np.argmax(model.predict(x_test_x), axis=1)\n",
        "  prpe.append(pred_y)\n",
        "  \n",
        "print(prpe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([37]), array([38]), array([37]), array([5]), array([38]), array([27]), array([42]), array([26]), array([35]), array([9]), array([17]), array([35]), array([42]), array([7]), array([37]), array([38]), array([8]), array([19]), array([2]), array([38]), array([37]), array([38]), array([3]), array([40]), array([1]), array([22]), array([33]), array([31]), array([0]), array([1]), array([26]), array([26]), array([21]), array([38]), array([42]), array([5]), array([38]), array([36]), array([22]), array([9]), array([6]), array([26]), array([9]), array([36]), array([33]), array([21]), array([1]), array([2]), array([24]), array([41]), array([39]), array([27]), array([9]), array([6]), array([24]), array([24]), array([8]), array([21]), array([23]), array([7]), array([24]), array([9]), array([8]), array([28]), array([16]), array([5]), array([33]), array([36]), array([12]), array([17]), array([18]), array([41]), array([8]), array([36]), array([7]), array([38]), array([19]), array([35]), array([25]), array([37]), array([4]), array([21]), array([36]), array([9]), array([2]), array([7]), array([36]), array([21]), array([36]), array([13]), array([21]), array([19]), array([41]), array([5]), array([19]), array([11]), array([41]), array([19]), array([31]), array([7]), array([8]), array([30]), array([32]), array([35]), array([1]), array([19]), array([40]), array([22]), array([37]), array([22]), array([38]), array([42]), array([8]), array([27]), array([26]), array([29]), array([38]), array([19]), array([22]), array([37]), array([24]), array([26]), array([8]), array([24]), array([38]), array([26]), array([9]), array([22]), array([22]), array([38]), array([8]), array([21]), array([7]), array([26]), array([7]), array([9]), array([20]), array([8]), array([22]), array([7]), array([37]), array([29]), array([9]), array([26]), array([26]), array([5]), array([28]), array([21]), array([22]), array([1]), array([26]), array([30]), array([8]), array([21]), array([13]), array([38]), array([28]), array([40]), array([35]), array([22]), array([20]), array([35]), array([19]), array([18]), array([21]), array([26]), array([5]), array([36]), array([28]), array([38]), array([28]), array([19]), array([2]), array([9]), array([24]), array([38]), array([30]), array([29]), array([16]), array([38]), array([38]), array([22]), array([41]), array([19]), array([19]), array([19]), array([11]), array([42]), array([42]), array([2]), array([21]), array([34]), array([8]), array([40]), array([37]), array([2]), array([16]), array([24]), array([23])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_zAphq4DOTu",
        "outputId": "67469f9f-521b-4c65-a714-279691739e31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# model.load_weights(\"/content/saved_models/traffic_1_final.h5\")\n",
        "\n",
        "for i in range(0,len(x_test[:10])):\n",
        "    img = x_test[i]\n",
        "    # img_copy = img.copy()\n",
        "    # plt.imshow(img_copy)\n",
        "    # plt.show()\n",
        "    label = y_test[i]\n",
        "    # print(label)\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "    # img = img / 255.\n",
        "    plt.imshow(img[0, :, :,0])\n",
        "    # plt.show()\n",
        "    eval = model.predict(img)\n",
        "    # print(eval)\n",
        "    eval = np.argmax(eval, axis=1)\n",
        "    print(eval)\n",
        "    # eval = traffic_dict[eval]\n",
        "    # print(eval)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37]\n",
            "[38]\n",
            "[37]\n",
            "[5]\n",
            "[38]\n",
            "[27]\n",
            "[42]\n",
            "[26]\n",
            "[35]\n",
            "[9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdFQaChcro3_",
        "outputId": "63221be8-6ebe-4c40-ec43-cdca66078f68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(y_test[:5])\n",
        "\n",
        "\n",
        "for i in  y_test[:5]:\n",
        "  eval = np.argmax(i) + 1\n",
        "  print(eval)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "40\n",
            "21\n",
            "40\n",
            "8\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-akW-WiyrrLc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}